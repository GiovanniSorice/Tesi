%!TEX root = ../dissertation.tex
\chapter{Conclusione}
\label{ch:conlusione}
All'interno di questo capitolo vengono esposte le considerazioni oggettive e soggettive riguardante l'esperienza fatta. 
\section{Consuntivo finale}
Il progetto ha avuto la durata inizialmente prevista, anche se sono state apportate alcune modifiche alla pianificazione iniziale. Per questo motivo, riporto la pianificazione aggiornata all'ultima settimana di stage.
\begin{itemize}
	\item Comprensione e analisi delle componenti del progetto: 56 ore;
	\item Realizzazione di pipeline \emph{batch} al fine di popolare \emph{\gls{data lake}} su cui svolgere processamenti periodici : 140 ore;
	\item Test e validazione pipeline \emph{batch} : 20 ore;
	\item Studio e applicazione del concetto di \emph{Data Ingestion}: 10  ore;
	\item Analisi, creazione e codifica \emph{job} di classificazione all'interno del Docker container:40 ore;
	\item Creazione e codifica \emph{job} rilevamento delle anomalie tra dati giornalieri: 15 ore;
	\item Studio e applicazione del concetto di \emph{Data Integration}: 10  ore;
	\item Integrazione finale tra le componenti principali della gestione dei dati: 19 ore;
	\item Documentazione progetto: 10 ore;
\end{itemize}
\section{Considerazione sugli obiettivi}
Di seguito vengono elencati in forma tabellare gli obiettivi con il loro relativo stato.
\newcolumntype{K}{>{\centering\arraybackslash}m{10cm}}
\normalsize
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|K|c|}
	\hline
	\textbf{Obiettivi obbligatori} &
	\textbf{Stato} 
	\endhead
	\hline
	Il sistema deve essere in grado di aggiornare periodicamente la concezione di normalità, per adattarsi al contesto dinamico. & Completato  \\ \hline 	 
	Il sistema deve essere in grado di ricevere i flussi \emph{batch} ed archiviarli dove desiderato. & Completato  \\ \hline 	 
	Il sistema deve essere in grado di processare i flussi \emph{batch} producendo i \emph{dataset} di output richiesti. & Completato  \\ \hline 	 
	I processi devono essere programmati per avviarsi periodicamente. & Completato  \\ \hline 	 
	\caption[Tabella degli obiettivi obbligatori]{Obiettivi obbligatori}
	\label{tabella:obiettiviO}
\end{longtable}
\renewcommand{\arraystretch}{1}
\normalsize
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|K|c|}
	\hline
	\textbf{Obiettivi desiderabili} &
	\textbf{Stato} 
	\endhead
	\hline
	Il sistema deve riuscire ad aggiornarsi continuamente senza interrompere l'erogazione del servizio. & Completato  \\ \hline 	 
	Il sistema deve essere in grado di scrivere i risultati su una struttura interrogabile via SQL. & Completato  \\ \hline 	 
	Il sistema deve poter scalare le risorse in base al volume di dati. & Completato  \\ \hline 	 
		\caption[Tabella degli obiettivi desiderabili]{Obiettivi desiderabili}
	\label{tabella:obiettiviD}
\end{longtable}
\renewcommand{\arraystretch}{1}
\normalsize
\renewcommand{\arraystretch}{1.5}
\begin{longtable}{|K|c|}
	\hline
	\textbf{Obiettivi facoltativi} &
	\textbf{Stato} 
	\endhead
	\hline
	Il sistema deve poter lavorare su dati archiviati su Elasticsearch. & Non implementato  \\ \hline 	 
	Il sistema deve poter essere in grado di scrivere i propri output su DB NoSQL. & Non implementato  \\ \hline 	 
	\caption[Tabella degli obiettivi facoltativi]{Obiettivi facoltativi}
	\label{tabella:obiettiviF}
\end{longtable}
\renewcommand{\arraystretch}{1}
Gli obiettivi obbligatori sono stati completati, come anche gli obiettivi desiderabili.
Gli obiettivi facoltativi sono risultati superflui alle richieste del cliente e per questo non sviluppati.

\section{Sviluppi futuri}
Il prodotto sviluppato presenta una buona capacità di gestione del dato, senza però sfruttare al massimo le capacità di classificazione, dato l'utilizzo di un semplice algoritmo di \emph{clustering}. Per questo motivo, consiglio di cambiare l'algoritmo di classificazione, scegliendone uno maggiormente performante e prestazionale. Inoltre, vi è da completare il passaggio di dati da classificare e quindi completare l'implementazione del produttore/consumatore Kafka.
\\
Data la modularità delle classi create per Google Dataflow, vi è la possibilità di aggiungere facilmente la fase di \emph{data ingestion} per altre tipologie di file o di schema \emph{XML} diversi da quelli trattati attualmente.
\section{Bilancio formativo}
I \emph{big data} e l'utilizzo di algoritmi di \emph{machine learning} per il riconoscimento delle anomalie, sono argomenti che mi hanno sempre incuriosito e che volevo approfondire maggiormente. All'interno dello stage ho avuto la possibilità di confrontarmi con svariate problematiche che mi hanno reso conscio del mio attuale bagaglio di conoscenze e che mi hanno aiutato a maturare il mio pensiero sul mondo della consulenza.
Le competenze da me acquisite durante questo periodo di stage, possono essere riassunte con il seguente elenco:
\begin{itemize}
	\item Concetti di gestione dei dati; 
	\item Nozioni di \emph{big data};
	\item Nozioni di Riconoscimento delle Anomalie;
	\item Utilizzo strumenti e servizi GCP (usati nel progetto);
	\item Creazione flusso di gestione dei dati;
	\item Utilizzo Apache NiFi;
	\item Utilizzo Apache AirFlow;
	\item Creazione DAGs AirFlow;
	\item Nozioni ed utilizzo di Apache Beam;
	\item Nozioni di Apache Spark;
	\item Utilizzo di Apache Spark MLlib;
	\item Condivisione delle informazioni tramite Google Data Studio;
	\item Utilizzo di Docker;
	\item Utilizzo di Kafka.
\end{itemize}
Il livello delle competenze acquisite non è paragonabile a quello di un professionista del settore, ma credo di avere raggiunto un livello discreto nella maggior parte degli strumenti utilizzati, un livello che mi permetterà di approfondire e di utilizzare tutto ciò che riguarda quegli strumenti e tecnologie.
Ciò che ho imparato e visto durante questa esperienza mi ha sicuramente aiutato a scegliere il percorso da seguire nei prossimi anni.
\section{Considerazioni personali}
Lo stage è stato più che positivo, sia sotto il profilo formativo che esperienziale. Questo non vuol dire che non ci siano state note negative o piccoli problemi durante questa esperienza, infatti trattandosi di un'esperienza all'interno di un'azienda di consulenza, la comunicazione con il cliente era spesso di fondamentale importanza, per questo credo che una comunicazione più fitta e veloce potesse produrre maggiori risultati. 
Nel complesso comunque, sono più che soddisfatto degli obiettivi raggiunti e del lavoro svolto all'interno del team di Data Reply.